{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cnblogs.com/charlotte77/p/7783261.html\n",
    "\n",
    "## 手写一个卷积神经网络\n",
    "\n",
    "4).进行前向传播\n",
    "\n",
    "\\begin{equation} \\begin{aligned} out_{o_{11}} &= activators(net_{o_{11}}) \\\\ &=max(0,net_{o_{11}}) = 1 \\end{aligned} \\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ConvLayer(object):\n",
    "    '''\n",
    "    参数含义：\n",
    "    input_width:输入图片尺寸——宽度\n",
    "    input_height:输入图片尺寸——长度\n",
    "    channel_number:通道数，彩色为3，灰色为1\n",
    "    filter_width:卷积核的宽\n",
    "    filter_height:卷积核的长\n",
    "    filter_number:卷积核数量\n",
    "    zero_padding：补零长度\n",
    "    stride:步长\n",
    "    activator:激活函数\n",
    "    learning_rate:学习率\n",
    "    '''\n",
    "    def __init__(self, input_width, input_height,\n",
    "                 channel_number, filter_width,\n",
    "                 filter_height, filter_number,\n",
    "                 zero_padding, stride, activator,\n",
    "                 learning_rate):\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.channel_number = channel_number\n",
    "        self.filter_width = filter_width\n",
    "        self.filter_height = filter_height\n",
    "        self.filter_number = filter_number\n",
    "        self.zero_padding = zero_padding\n",
    "        self.stride = stride\n",
    "        self.output_width = \\\n",
    "            ConvLayer.calculate_output_size(\n",
    "            self.input_width, filter_width, zero_padding,\n",
    "            stride)\n",
    "        self.output_height = \\\n",
    "            ConvLayer.calculate_output_size(\n",
    "            self.input_height, filter_height, zero_padding,\n",
    "            stride)\n",
    "        print(self.filter_number,\n",
    "            self.output_height, self.output_width)\n",
    "        self.output_array = np.zeros((self.filter_number,\n",
    "            self.output_height, self.output_width))\n",
    "        self.filters = []\n",
    "        for i in range(filter_number):\n",
    "            self.filters.append(Filter(filter_width,\n",
    "                filter_height, self.channel_number))\n",
    "        self.activator = activator\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def calculate_output_size(input_size,\n",
    "        filter_size, zero_padding, stride):\n",
    "        return (input_size - filter_size +\n",
    "                 2 * zero_padding) // stride + 1\n",
    "    \n",
    "    def forward(self, input_array):\n",
    "        '''\n",
    "        计算卷积层的输出\n",
    "        输出结果保存在self.output_array\n",
    "        '''\n",
    "        self.input_array = input_array\n",
    "        self.padded_input_array = padding(input_array,\n",
    "            self.zero_padding)\n",
    "        for f in range(self.filter_number):\n",
    "            filter = self.filters[f]\n",
    "            conv(self.padded_input_array,\n",
    "                filter.get_weights(), self.output_array[f],\n",
    "                self.stride, filter.get_bias())\n",
    "        element_wise_op(self.output_array,\n",
    "                        self.activator.forward)\n",
    "        \n",
    "    def element_wise_op(array, op):\n",
    "         for i in np.nditer(array,\n",
    "            op_flags=['readwrite']):\n",
    "            i[...] = op(i)\n",
    "            \n",
    "    def backward(self, input_array, sensitivity_array, \n",
    "                 activator):\n",
    "        '''\n",
    "        计算传递给前一层的误差项，以及计算每个权重的梯度\n",
    "        前一层的误差项保存在self.delta_array\n",
    "        梯度保存在Filter对象的weights_grad\n",
    "        '''\n",
    "        self.forward(input_array)\n",
    "        self.bp_sensitivity_map(sensitivity_array,\n",
    "                                activator)\n",
    "        self.bp_gradient(sensitivity_array)\n",
    "        \n",
    "    def update(self):\n",
    "        '''\n",
    "        按照梯度下降，更新权重\n",
    "        '''\n",
    "        for filter in self.filters:\n",
    "            filter.update(self.learning_rate)\n",
    "\n",
    "    def bp_sensitivity_map(self, sensitivity_array,\n",
    "                           activator):\n",
    "        '''\n",
    "        计算传递到上一层的sensitivity map\n",
    "        sensitivity_array: 本层的sensitivity map\n",
    "        activator: 上一层的激活函数\n",
    "        '''\n",
    "        # 处理卷积步长，对原始sensitivity map进行扩展\n",
    "        expanded_array = self.expand_sensitivity_map(\n",
    "            sensitivity_array)\n",
    "        # full卷积，对sensitivitiy map进行zero padding\n",
    "        # 虽然原始输入的zero padding单元也会获得残差\n",
    "        # 但这个残差不需要继续向上传递，因此就不计算了\n",
    "        expanded_width = expanded_array.shape[2]\n",
    "        zp = (self.input_width +  \n",
    "              self.filter_width - 1 - expanded_width) // 2\n",
    "        padded_array = padding(expanded_array, zp)\n",
    "        # 初始化delta_array，用于保存传递到上一层的\n",
    "        # sensitivity map\n",
    "        self.delta_array = self.create_delta_array()\n",
    "        # 对于具有多个filter的卷积层来说，最终传递到上一层的\n",
    "        # sensitivity map相当于所有的filter的\n",
    "        # sensitivity map之和\n",
    "        for f in range(self.filter_number):\n",
    "            filter = self.filters[f]\n",
    "            # 将filter权重翻转180度\n",
    "            flipped_weights = np.array(list(map(\n",
    "                lambda i: np.rot90(i, 2), \n",
    "                filter.get_weights())))\n",
    "            # 计算与一个filter对应的delta_array\n",
    "            delta_array = self.create_delta_array()\n",
    "            for d in range(delta_array.shape[0]):\n",
    "                print('shit', flipped_weights)\n",
    "                conv(padded_array[f], flipped_weights[d],\n",
    "                    delta_array[d], 1, 0)\n",
    "            self.delta_array += delta_array\n",
    "        # 将计算结果与激活函数的偏导数做element-wise乘法操作\n",
    "        derivative_array = np.array(self.input_array)\n",
    "        element_wise_op(derivative_array, \n",
    "                        activator.backward)\n",
    "        self.delta_array *= derivative_array\n",
    "\n",
    "    def bp_gradient(self, sensitivity_array):\n",
    "        # 处理卷积步长，对原始sensitivity map进行扩展\n",
    "        expanded_array = self.expand_sensitivity_map(\n",
    "            sensitivity_array)\n",
    "        for f in range(self.filter_number):\n",
    "            # 计算每个权重的梯度\n",
    "            filter = self.filters[f]\n",
    "            for d in range(filter.weights.shape[0]):\n",
    "                conv(self.padded_input_array[d], \n",
    "                     expanded_array[f],\n",
    "                     filter.weights_grad[d], 1, 0)\n",
    "            # 计算偏置项的梯度\n",
    "            filter.bias_grad = expanded_array[f].sum()\n",
    "\n",
    "    def expand_sensitivity_map(self, sensitivity_array):\n",
    "        depth = sensitivity_array.shape[0]\n",
    "        # 确定扩展后sensitivity map的大小\n",
    "        # 计算stride为1时sensitivity map的大小\n",
    "        expanded_width = (self.input_width - \n",
    "            self.filter_width + 2 * self.zero_padding + 1)\n",
    "        expanded_height = (self.input_height - \n",
    "            self.filter_height + 2 * self.zero_padding + 1)\n",
    "        # 构建新的sensitivity_map\n",
    "        expand_array = np.zeros((depth, expanded_height, \n",
    "                                 expanded_width))\n",
    "        # 从原始sensitivity map拷贝误差值\n",
    "        for i in range(self.output_height):\n",
    "            for j in range(self.output_width):\n",
    "                i_pos = i * self.stride\n",
    "                j_pos = j * self.stride\n",
    "                expand_array[:,i_pos,j_pos] = \\\n",
    "                    sensitivity_array[:,i,j]\n",
    "        return expand_array\n",
    "\n",
    "    def create_delta_array(self):\n",
    "        return np.zeros((self.channel_number,\n",
    "            self.input_height, self.input_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityActivator(object):\n",
    "    def forward(self, weighted_input):\n",
    "        return weighted_input\n",
    "\n",
    "    def backward(self, output):\n",
    "        return 1\n",
    "\n",
    "class ReluActivator(object):\n",
    "    def forward(self, weighted_input):\n",
    "        #return weighted_input\n",
    "        return max(0, weighted_input)\n",
    "\n",
    "    def backward(self, output):\n",
    "        return 1 if output > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidActivator(object):\n",
    "    def forward(self, weighted_input):\n",
    "        return 1.0 // (1.0 + np.exp(-weighted_input))\n",
    "    def backward(self, output):\n",
    "        return output * (1 - output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存卷积层的参数和梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filter(object):\n",
    "    def __init__(self, width, height, depth):\n",
    "        #初始权重\n",
    "        self.weights = np.random.uniform(-1e-4, 1e-4,\n",
    "            (depth, height, width))\n",
    "        #初始偏置\n",
    "        self.bias = 0\n",
    "        self.weights_grad = np.zeros(\n",
    "            self.weights.shape)\n",
    "        self.bias_grad = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'filter weights:\\n%s\\nbias:\\n%s' % (\n",
    "            repr(self.weights), repr(self.bias))\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "    def get_bias(self):\n",
    "        return self.bias\n",
    "\n",
    "    def update(self, learning_rate):\n",
    "        self.weights -= learning_rate * self.weights_grad\n",
    "        self.bias -= learning_rate * self.bias_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积层的前向传播\n",
    "\n",
    "1).获取卷积区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取卷积区域\n",
    "def get_patch(input_array, i, j, filter_width,\n",
    "              filter_height, stride):\n",
    "    '''\n",
    "    从输入数组中获取本次卷积的区域，\n",
    "    自动适配输入为2D和3D的情况\n",
    "    '''\n",
    "    start_i = i * stride\n",
    "    start_j = j * stride\n",
    "    if input_array.ndim == 2:\n",
    "        input_array_conv = input_array[\n",
    "            start_i : start_i + filter_height,\n",
    "            start_j : start_j + filter_width]\n",
    "        print(\"input_array_conv:\",input_array_conv)\n",
    "        return input_array_conv\n",
    "\n",
    "    elif input_array.ndim == 3:\n",
    "        input_array_conv = input_array[:,\n",
    "            start_i : start_i + filter_height,\n",
    "            start_j : start_j + filter_width]\n",
    "        print(\"input_array_conv:\",input_array_conv)\n",
    "        return input_array_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2).进行卷积运算\n",
    "\n",
    "\n",
    "\\begin{equation} \n",
    "    \\begin{aligned} \n",
    "        \\ net_{o_{11}}&= conv (input,filter)\\\\  &= i_{11} \\times h_{11} + i_{12} \\times h_{12} +i_{21} \\times h_{21} + i_{22} \\times h_{22}\\\\  &=1 \\times 1 + 0 \\times (-1) +1 \\times 1 + 1 \\times (-1)=1 \n",
    "    \\end{aligned} \n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(input_array,\n",
    "         kernel_array,\n",
    "         output_array,\n",
    "         stride, bias):\n",
    "    '''\n",
    "    计算卷积，自动适配输入为2D和3D的情况\n",
    "    '''\n",
    "    channel_number = input_array.ndim\n",
    "    output_width = output_array.shape[1]\n",
    "    output_height = output_array.shape[0]\n",
    "    kernel_width = kernel_array.shape[-1]\n",
    "    kernel_height = kernel_array.shape[-2]\n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            output_array[i][j] = (\n",
    "                get_patch(input_array, i, j, kernel_width,\n",
    "                    kernel_height, stride) * kernel_array\n",
    "                ).sum() + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3).增加zero_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#增加Zero padding\n",
    "def padding(input_array, zp):\n",
    "    '''\n",
    "    为数组增加Zero padding，自动适配输入为2D和3D的情况\n",
    "    '''\n",
    "    if zp == 0:\n",
    "        return input_array\n",
    "    else:\n",
    "        if input_array.ndim == 3:\n",
    "            input_width = input_array.shape[2]\n",
    "            input_height = input_array.shape[1]\n",
    "            input_depth = input_array.shape[0]\n",
    "            padded_array = np.zeros((\n",
    "                input_depth,\n",
    "                input_height + 2 * zp,\n",
    "                input_width + 2 * zp))\n",
    "            padded_array[:,\n",
    "                zp : zp + input_height,\n",
    "                zp : zp + input_width] = input_array\n",
    "            return padded_array\n",
    "        elif input_array.ndim == 2:\n",
    "            input_width = input_array.shape[1]\n",
    "            input_height = input_array.shape[0]\n",
    "            padded_array = np.zeros((\n",
    "                input_height + 2 * zp,\n",
    "                input_width + 2 * zp))\n",
    "            padded_array[zp : zp + input_height,\n",
    "                zp : zp + input_width] = input_array\n",
    "            return padded_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.卷积层的反向传播\n",
    "\n",
    "1).将误差传递到上一层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp_sensitivity_map(self, sensitivity_array,\n",
    "                           activator):\n",
    "        '''\n",
    "        计算传递到上一层的sensitivity map\n",
    "        sensitivity_array: 本层的sensitivity map\n",
    "        activator: 上一层的激活函数\n",
    "        '''\n",
    "        # 处理卷积步长，对原始sensitivity map进行扩展\n",
    "        expanded_array = self.expand_sensitivity_map(\n",
    "            sensitivity_array)\n",
    "        # full卷积，对sensitivitiy map进行zero padding\n",
    "        # 虽然原始输入的zero padding单元也会获得残差\n",
    "        # 但这个残差不需要继续向上传递，因此就不计算了\n",
    "        expanded_width = expanded_array.shape[2]\n",
    "        zp = (self.input_width +\n",
    "              self.filter_width - 1 - expanded_width) // 2\n",
    "        padded_array = padding(expanded_array, zp)\n",
    "        # 初始化delta_array，用于保存传递到上一层的\n",
    "        # sensitivity map\n",
    "        self.delta_array = self.create_delta_array()\n",
    "        # 对于具有多个filter的卷积层来说，最终传递到上一层的\n",
    "        # sensitivity map相当于所有的filter的\n",
    "        # sensitivity map之和\n",
    "        for f in range(self.filter_number):\n",
    "            filter = self.filters[f]\n",
    "            # 将filter权重翻转180度\n",
    "            flipped_weights = np.array(map(\n",
    "                lambda i: np.rot90(i, 2),\n",
    "                filter.get_weights()))\n",
    "            # 计算与一个filter对应的delta_array\n",
    "            delta_array = self.create_delta_array()\n",
    "            for d in range(delta_array.shape[0]):\n",
    "                conv(padded_array[f], flipped_weights[d],\n",
    "                    delta_array[d], 1, 0)\n",
    "            self.delta_array += delta_array\n",
    "        # 将计算结果与激活函数的偏导数做element-wise乘法操作\n",
    "        derivative_array = np.array(self.input_array)\n",
    "        element_wise_op(derivative_array,\n",
    "                        activator.backward)\n",
    "        self.delta_array *= derivative_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_delta_array(self):\n",
    "    return np.zeros((self.channel_number,\n",
    "             self.input_height, self.input_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp_gradient(self, sensitivity_array):\n",
    "        # 处理卷积步长，对原始sensitivity map进行扩展\n",
    "        expanded_array = self.expand_sensitivity_map(\n",
    "            sensitivity_array)\n",
    "        for f in range(self.filter_number):\n",
    "            # 计算每个权重的梯度\n",
    "            filter = self.filters[f]\n",
    "            for d in range(filter.weights.shape[0]):\n",
    "                conv(self.padded_input_array[d],\n",
    "                     expanded_array[f],\n",
    "                     filter.weights_grad[d], 1, 0)\n",
    "            # 计算偏置项的梯度\n",
    "            filter.bias_grad = expanded_array[f].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(self):\n",
    "    '''\n",
    "         按照梯度下降，更新权重\n",
    "    '''\n",
    "    for filter in self.filters:\n",
    "        filter.update(self.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.MaxPooling层的训练\n",
    "\n",
    "1).定义MaxPooling类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolingLayer(object):\n",
    "    def __init__(self, input_width, input_height,\n",
    "                 channel_number, filter_width,\n",
    "                 filter_height, stride):\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.channel_number = channel_number\n",
    "        self.filter_width = filter_width\n",
    "        self.filter_height = filter_height\n",
    "        self.stride = stride\n",
    "        self.output_width = (input_width -\n",
    "            filter_width) // self.stride + 1\n",
    "        self.output_height = (input_height -\n",
    "            filter_height) // self.stride + 1\n",
    "        self.output_array = np.zeros((self.channel_number,\n",
    "            self.output_height, self.output_width))\n",
    "    # 前向传播\n",
    "    def forward(self, input_array):\n",
    "        for d in range(self.channel_number):\n",
    "            for i in range(self.output_height):\n",
    "                for j in range(self.output_width):\n",
    "                    self.output_array[d,i,j] = (\n",
    "                        get_patch(input_array[d], i, j,\n",
    "                            self.filter_width,\n",
    "                            self.filter_height,\n",
    "                            self.stride).max())\n",
    "                    \n",
    "    #反向传播\n",
    "    def backward(self, input_array, sensitivity_array):\n",
    "        self.delta_array = np.zeros(input_array.shape)\n",
    "        for d in range(self.channel_number):\n",
    "            for i in range(self.output_height):\n",
    "                for j in range(self.output_width):\n",
    "                    patch_array = get_patch(\n",
    "                        input_array[d], i, j,\n",
    "                        self.filter_width,\n",
    "                        self.filter_height,\n",
    "                        self.stride)\n",
    "                    k, l = get_max_index(patch_array)\n",
    "                    self.delta_array[d,\n",
    "                        i * self.stride + k,\n",
    "                        j * self.stride + l] = \\\n",
    "                        sensitivity_array[d,i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_test():\n",
    "    a = np.array(\n",
    "        [[[0,1,1,0,2],\n",
    "          [2,2,2,2,1],\n",
    "          [1,0,0,2,0],\n",
    "          [0,1,1,0,0],\n",
    "          [1,2,0,0,2]],\n",
    "         [[1,0,2,2,0],\n",
    "          [0,0,0,2,0],\n",
    "          [1,2,1,2,1],\n",
    "          [1,0,0,0,0],\n",
    "          [1,2,1,1,1]],\n",
    "         [[2,1,2,0,0],\n",
    "          [1,0,0,1,0],\n",
    "          [0,2,1,0,1],\n",
    "          [0,1,2,2,2],\n",
    "          [2,1,0,0,1]]])\n",
    "    b = np.array(\n",
    "        [[[0,1,1],\n",
    "          [2,2,2],\n",
    "          [1,0,0]],\n",
    "         [[1,0,2],\n",
    "          [0,0,0],\n",
    "          [1,2,1]]])\n",
    "    cl = ConvLayer(5,5,3,3,3,2,1,2,IdentityActivator(),0.001)\n",
    "    cl.filters[0].weights = np.array(\n",
    "        [[[-1,1,0],\n",
    "          [0,1,0],\n",
    "          [0,1,1]],\n",
    "         [[-1,-1,0],\n",
    "          [0,0,0],\n",
    "          [0,-1,0]],\n",
    "         [[0,0,-1],\n",
    "          [0,1,0],\n",
    "          [1,-1,-1]]], dtype=np.float64)\n",
    "    cl.filters[0].bias=1\n",
    "    cl.filters[1].weights = np.array(\n",
    "        [[[1,1,-1],\n",
    "          [-1,-1,1],\n",
    "          [0,-1,1]],\n",
    "         [[0,1,0],\n",
    "         [-1,0,-1],\n",
    "          [-1,1,0]],\n",
    "         [[-1,0,0],\n",
    "          [-1,0,1],\n",
    "          [-1,0,0]]], dtype=np.float64)\n",
    "    return a, b, cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3 3\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 2. 2.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 2. 1.]\n",
      "  [0. 1. 0.]]]\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [1. 1. 0.]\n",
      "  [2. 2. 2.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 2. 2.]\n",
      "  [0. 0. 2.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [1. 2. 0.]\n",
      "  [0. 0. 1.]]]\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [0. 2. 0.]\n",
      "  [2. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [2. 0. 0.]\n",
      "  [2. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [1. 0. 0.]]]\n",
      "input_array_conv: [[[0. 2. 2.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 1. 2.]\n",
      "  [0. 1. 0.]]\n",
      "\n",
      " [[0. 1. 0.]\n",
      "  [0. 0. 2.]\n",
      "  [0. 0. 1.]]]\n",
      "input_array_conv: [[[2. 2. 2.]\n",
      "  [0. 0. 2.]\n",
      "  [1. 1. 0.]]\n",
      "\n",
      " [[0. 0. 2.]\n",
      "  [2. 1. 2.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1.]\n",
      "  [2. 1. 0.]\n",
      "  [1. 2. 2.]]]\n",
      "input_array_conv: [[[2. 1. 0.]\n",
      "  [2. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[2. 0. 0.]\n",
      "  [2. 1. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [2. 2. 0.]]]\n",
      "input_array_conv: [[[0. 0. 1.]\n",
      "  [0. 1. 2.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0.]\n",
      "  [0. 1. 2.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1.]\n",
      "  [0. 2. 1.]\n",
      "  [0. 0. 0.]]]\n",
      "input_array_conv: [[[1. 1. 0.]\n",
      "  [2. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [2. 1. 1.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[1. 2. 2.]\n",
      "  [1. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [0. 2. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [1. 1. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[2. 2. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 2. 2.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 2. 1.]\n",
      "  [0. 1. 0.]]]\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [1. 1. 0.]\n",
      "  [2. 2. 2.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 2. 2.]\n",
      "  [0. 0. 2.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [1. 2. 0.]\n",
      "  [0. 0. 1.]]]\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [0. 2. 0.]\n",
      "  [2. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [2. 0. 0.]\n",
      "  [2. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [1. 0. 0.]]]\n",
      "input_array_conv: [[[0. 2. 2.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 1. 2.]\n",
      "  [0. 1. 0.]]\n",
      "\n",
      " [[0. 1. 0.]\n",
      "  [0. 0. 2.]\n",
      "  [0. 0. 1.]]]\n",
      "input_array_conv: [[[2. 2. 2.]\n",
      "  [0. 0. 2.]\n",
      "  [1. 1. 0.]]\n",
      "\n",
      " [[0. 0. 2.]\n",
      "  [2. 1. 2.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1.]\n",
      "  [2. 1. 0.]\n",
      "  [1. 2. 2.]]]\n",
      "input_array_conv: [[[2. 1. 0.]\n",
      "  [2. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[2. 0. 0.]\n",
      "  [2. 1. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [2. 2. 0.]]]\n",
      "input_array_conv: [[[0. 0. 1.]\n",
      "  [0. 1. 2.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0.]\n",
      "  [0. 1. 2.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1.]\n",
      "  [0. 2. 1.]\n",
      "  [0. 0. 0.]]]\n",
      "input_array_conv: [[[1. 1. 0.]\n",
      "  [2. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [2. 1. 1.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[1. 2. 2.]\n",
      "  [1. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [0. 2. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [1. 1. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[2. 2. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "前向传播结果: [[[ 6.  7.  5.]\n",
      "  [ 3. -1. -1.]\n",
      "  [ 2. -1.  4.]]\n",
      "\n",
      " [[ 2. -5. -8.]\n",
      "  [ 1. -4. -4.]\n",
      "  [ 0. -5. -5.]]]\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 2. 2.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 2. 1.]\n",
      "  [0. 1. 0.]]]\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [1. 1. 0.]\n",
      "  [2. 2. 2.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 2. 2.]\n",
      "  [0. 0. 2.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [1. 2. 0.]\n",
      "  [0. 0. 1.]]]\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [0. 2. 0.]\n",
      "  [2. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [2. 0. 0.]\n",
      "  [2. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [1. 0. 0.]]]\n",
      "input_array_conv: [[[0. 2. 2.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 1. 2.]\n",
      "  [0. 1. 0.]]\n",
      "\n",
      " [[0. 1. 0.]\n",
      "  [0. 0. 2.]\n",
      "  [0. 0. 1.]]]\n",
      "input_array_conv: [[[2. 2. 2.]\n",
      "  [0. 0. 2.]\n",
      "  [1. 1. 0.]]\n",
      "\n",
      " [[0. 0. 2.]\n",
      "  [2. 1. 2.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1.]\n",
      "  [2. 1. 0.]\n",
      "  [1. 2. 2.]]]\n",
      "input_array_conv: [[[2. 1. 0.]\n",
      "  [2. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[2. 0. 0.]\n",
      "  [2. 1. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [2. 2. 0.]]]\n",
      "input_array_conv: [[[0. 0. 1.]\n",
      "  [0. 1. 2.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0.]\n",
      "  [0. 1. 2.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1.]\n",
      "  [0. 2. 1.]\n",
      "  [0. 0. 0.]]]\n",
      "input_array_conv: [[[1. 1. 0.]\n",
      "  [2. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [2. 1. 1.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[1. 2. 2.]\n",
      "  [1. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [0. 2. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [1. 1. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[2. 2. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 2. 2.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 2. 1.]\n",
      "  [0. 1. 0.]]]\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [1. 1. 0.]\n",
      "  [2. 2. 2.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 2. 2.]\n",
      "  [0. 0. 2.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [1. 2. 0.]\n",
      "  [0. 0. 1.]]]\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [0. 2. 0.]\n",
      "  [2. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [2. 0. 0.]\n",
      "  [2. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [1. 0. 0.]]]\n",
      "input_array_conv: [[[0. 2. 2.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 1. 2.]\n",
      "  [0. 1. 0.]]\n",
      "\n",
      " [[0. 1. 0.]\n",
      "  [0. 0. 2.]\n",
      "  [0. 0. 1.]]]\n",
      "input_array_conv: [[[2. 2. 2.]\n",
      "  [0. 0. 2.]\n",
      "  [1. 1. 0.]]\n",
      "\n",
      " [[0. 0. 2.]\n",
      "  [2. 1. 2.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1.]\n",
      "  [2. 1. 0.]\n",
      "  [1. 2. 2.]]]\n",
      "input_array_conv: [[[2. 1. 0.]\n",
      "  [2. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[2. 0. 0.]\n",
      "  [2. 1. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [2. 2. 0.]]]\n",
      "input_array_conv: [[[0. 0. 1.]\n",
      "  [0. 1. 2.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0.]\n",
      "  [0. 1. 2.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1.]\n",
      "  [0. 2. 1.]\n",
      "  [0. 0. 0.]]]\n",
      "input_array_conv: [[[1. 1. 0.]\n",
      "  [2. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [2. 1. 1.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[1. 2. 2.]\n",
      "  [1. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "input_array_conv: [[[0. 0. 0.]\n",
      "  [0. 2. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [1. 1. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[2. 2. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "shit [[[ 1.  1.  0.]\n",
      "  [ 0.  1.  0.]\n",
      "  [ 0.  1. -1.]]\n",
      "\n",
      " [[ 0. -1.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0. -1. -1.]]\n",
      "\n",
      " [[-1. -1.  1.]\n",
      "  [ 0.  1.  0.]\n",
      "  [-1.  0.  0.]]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [1. 0. 1.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 2. 0.]]\n",
      "input_array_conv: [[0. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [2. 0. 2.]]\n",
      "input_array_conv: [[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 2. 0.]]\n",
      "input_array_conv: [[1. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [2. 0. 2.]]\n",
      "input_array_conv: [[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 2. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [2. 0. 2.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [2. 0. 2.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 2. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "input_array_conv: [[2. 0. 2.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "input_array_conv: [[0. 2. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[2. 0. 2.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 2. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "shit [[[ 1.  1.  0.]\n",
      "  [ 0.  1.  0.]\n",
      "  [ 0.  1. -1.]]\n",
      "\n",
      " [[ 0. -1.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0. -1. -1.]]\n",
      "\n",
      " [[-1. -1.  1.]\n",
      "  [ 0.  1.  0.]\n",
      "  [-1.  0.  0.]]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [1. 0. 1.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 2. 0.]]\n",
      "input_array_conv: [[0. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [2. 0. 2.]]\n",
      "input_array_conv: [[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 2. 0.]]\n",
      "input_array_conv: [[1. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [2. 0. 2.]]\n",
      "input_array_conv: [[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 2. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [2. 0. 2.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [2. 0. 2.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 2. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "input_array_conv: [[2. 0. 2.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "input_array_conv: [[0. 2. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[2. 0. 2.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 2. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "shit [[[ 1.  1.  0.]\n",
      "  [ 0.  1.  0.]\n",
      "  [ 0.  1. -1.]]\n",
      "\n",
      " [[ 0. -1.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0. -1. -1.]]\n",
      "\n",
      " [[-1. -1.  1.]\n",
      "  [ 0.  1.  0.]\n",
      "  [-1.  0.  0.]]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [1. 0. 1.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 2. 0.]]\n",
      "input_array_conv: [[0. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [2. 0. 2.]]\n",
      "input_array_conv: [[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 2. 0.]]\n",
      "input_array_conv: [[1. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [2. 0. 2.]]\n",
      "input_array_conv: [[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 2. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [2. 0. 2.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [2. 0. 2.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 2. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "input_array_conv: [[2. 0. 2.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "input_array_conv: [[0. 2. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[2. 0. 2.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 2. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "shit [[[ 1. -1.  0.]\n",
      "  [ 1. -1. -1.]\n",
      "  [-1.  1.  1.]]\n",
      "\n",
      " [[ 0.  1. -1.]\n",
      "  [-1.  0. -1.]\n",
      "  [ 0.  1.  0.]]\n",
      "\n",
      " [[ 0.  0. -1.]\n",
      "  [ 1.  0. -1.]\n",
      "  [ 0.  0. -1.]]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 2.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 2.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 2. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 2.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 2. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [2. 0. 1.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [1. 0. 2.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [2. 0. 1.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "shit [[[ 1. -1.  0.]\n",
      "  [ 1. -1. -1.]\n",
      "  [-1.  1.  1.]]\n",
      "\n",
      " [[ 0.  1. -1.]\n",
      "  [-1.  0. -1.]\n",
      "  [ 0.  1.  0.]]\n",
      "\n",
      " [[ 0.  0. -1.]\n",
      "  [ 1.  0. -1.]\n",
      "  [ 0.  0. -1.]]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 2.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 2.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 2. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 2.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 2. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [2. 0. 1.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [1. 0. 2.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [2. 0. 1.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "shit [[[ 1. -1.  0.]\n",
      "  [ 1. -1. -1.]\n",
      "  [-1.  1.  1.]]\n",
      "\n",
      " [[ 0.  1. -1.]\n",
      "  [-1.  0. -1.]\n",
      "  [ 0.  1.  0.]]\n",
      "\n",
      " [[ 0.  0. -1.]\n",
      "  [ 1.  0. -1.]\n",
      "  [ 0.  0. -1.]]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 2.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 2.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 2. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 2.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 2. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [2. 0. 1.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [1. 0. 2.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [2. 0. 1.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [0. 2. 2. 2. 2.]\n",
      " [0. 1. 0. 0. 2.]\n",
      " [0. 0. 1. 1. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 2.]\n",
      " [2. 2. 2. 2. 1.]\n",
      " [1. 0. 0. 2. 0.]\n",
      " [0. 1. 1. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 2. 0.]\n",
      " [2. 2. 2. 1. 0.]\n",
      " [0. 0. 2. 0. 0.]\n",
      " [1. 1. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 1. 1. 0.]\n",
      " [0. 2. 2. 2. 2.]\n",
      " [0. 1. 0. 0. 2.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [0. 1. 2. 0. 0.]]\n",
      "input_array_conv: [[0. 1. 1. 0. 2.]\n",
      " [2. 2. 2. 2. 1.]\n",
      " [1. 0. 0. 2. 0.]\n",
      " [0. 1. 1. 0. 0.]\n",
      " [1. 2. 0. 0. 2.]]\n",
      "input_array_conv: [[1. 1. 0. 2. 0.]\n",
      " [2. 2. 2. 1. 0.]\n",
      " [0. 0. 2. 0. 0.]\n",
      " [1. 1. 0. 0. 0.]\n",
      " [2. 0. 0. 2. 0.]]\n",
      "input_array_conv: [[0. 2. 2. 2. 2.]\n",
      " [0. 1. 0. 0. 2.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [0. 1. 2. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[2. 2. 2. 2. 1.]\n",
      " [1. 0. 0. 2. 0.]\n",
      " [0. 1. 1. 0. 0.]\n",
      " [1. 2. 0. 0. 2.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[2. 2. 2. 1. 0.]\n",
      " [0. 0. 2. 0. 0.]\n",
      " [1. 1. 0. 0. 0.]\n",
      " [2. 0. 0. 2. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 2. 2.]\n",
      " [0. 0. 0. 0. 2.]\n",
      " [0. 1. 2. 1. 2.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [1. 0. 2. 2. 0.]\n",
      " [0. 0. 0. 2. 0.]\n",
      " [1. 2. 1. 2. 1.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [0. 2. 2. 0. 0.]\n",
      " [0. 0. 2. 0. 0.]\n",
      " [2. 1. 2. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 1. 0. 2. 2.]\n",
      " [0. 0. 0. 0. 2.]\n",
      " [0. 1. 2. 1. 2.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 2. 1. 1.]]\n",
      "input_array_conv: [[1. 0. 2. 2. 0.]\n",
      " [0. 0. 0. 2. 0.]\n",
      " [1. 2. 1. 2. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 2. 1. 1. 1.]]\n",
      "input_array_conv: [[0. 2. 2. 0. 0.]\n",
      " [0. 0. 2. 0. 0.]\n",
      " [2. 1. 2. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [2. 1. 1. 1. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 2.]\n",
      " [0. 1. 2. 1. 2.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 2. 1. 1.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 2. 0.]\n",
      " [1. 2. 1. 2. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 2. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 2. 0. 0.]\n",
      " [2. 1. 2. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [2. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [0. 2. 1. 2. 0.]\n",
      " [0. 1. 0. 0. 1.]\n",
      " [0. 0. 2. 1. 0.]\n",
      " [0. 0. 1. 2. 2.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [2. 1. 2. 0. 0.]\n",
      " [1. 0. 0. 1. 0.]\n",
      " [0. 2. 1. 0. 1.]\n",
      " [0. 1. 2. 2. 2.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [1. 2. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [2. 1. 0. 1. 0.]\n",
      " [1. 2. 2. 2. 0.]]\n",
      "input_array_conv: [[0. 2. 1. 2. 0.]\n",
      " [0. 1. 0. 0. 1.]\n",
      " [0. 0. 2. 1. 0.]\n",
      " [0. 0. 1. 2. 2.]\n",
      " [0. 2. 1. 0. 0.]]\n",
      "input_array_conv: [[2. 1. 2. 0. 0.]\n",
      " [1. 0. 0. 1. 0.]\n",
      " [0. 2. 1. 0. 1.]\n",
      " [0. 1. 2. 2. 2.]\n",
      " [2. 1. 0. 0. 1.]]\n",
      "input_array_conv: [[1. 2. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [2. 1. 0. 1. 0.]\n",
      " [1. 2. 2. 2. 0.]\n",
      " [1. 0. 0. 1. 0.]]\n",
      "input_array_conv: [[0. 1. 0. 0. 1.]\n",
      " [0. 0. 2. 1. 0.]\n",
      " [0. 0. 1. 2. 2.]\n",
      " [0. 2. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[1. 0. 0. 1. 0.]\n",
      " [0. 2. 1. 0. 1.]\n",
      " [0. 1. 2. 2. 2.]\n",
      " [2. 1. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 1. 0. 0.]\n",
      " [2. 1. 0. 1. 0.]\n",
      " [1. 2. 2. 2. 0.]\n",
      " [1. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [0. 2. 2. 2. 2.]\n",
      " [0. 1. 0. 0. 2.]\n",
      " [0. 0. 1. 1. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 2.]\n",
      " [2. 2. 2. 2. 1.]\n",
      " [1. 0. 0. 2. 0.]\n",
      " [0. 1. 1. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 2. 0.]\n",
      " [2. 2. 2. 1. 0.]\n",
      " [0. 0. 2. 0. 0.]\n",
      " [1. 1. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 1. 1. 0.]\n",
      " [0. 2. 2. 2. 2.]\n",
      " [0. 1. 0. 0. 2.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [0. 1. 2. 0. 0.]]\n",
      "input_array_conv: [[0. 1. 1. 0. 2.]\n",
      " [2. 2. 2. 2. 1.]\n",
      " [1. 0. 0. 2. 0.]\n",
      " [0. 1. 1. 0. 0.]\n",
      " [1. 2. 0. 0. 2.]]\n",
      "input_array_conv: [[1. 1. 0. 2. 0.]\n",
      " [2. 2. 2. 1. 0.]\n",
      " [0. 0. 2. 0. 0.]\n",
      " [1. 1. 0. 0. 0.]\n",
      " [2. 0. 0. 2. 0.]]\n",
      "input_array_conv: [[0. 2. 2. 2. 2.]\n",
      " [0. 1. 0. 0. 2.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [0. 1. 2. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[2. 2. 2. 2. 1.]\n",
      " [1. 0. 0. 2. 0.]\n",
      " [0. 1. 1. 0. 0.]\n",
      " [1. 2. 0. 0. 2.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[2. 2. 2. 1. 0.]\n",
      " [0. 0. 2. 0. 0.]\n",
      " [1. 1. 0. 0. 0.]\n",
      " [2. 0. 0. 2. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 2. 2.]\n",
      " [0. 0. 0. 0. 2.]\n",
      " [0. 1. 2. 1. 2.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [1. 0. 2. 2. 0.]\n",
      " [0. 0. 0. 2. 0.]\n",
      " [1. 2. 1. 2. 1.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [0. 2. 2. 0. 0.]\n",
      " [0. 0. 2. 0. 0.]\n",
      " [2. 1. 2. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 1. 0. 2. 2.]\n",
      " [0. 0. 0. 0. 2.]\n",
      " [0. 1. 2. 1. 2.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 2. 1. 1.]]\n",
      "input_array_conv: [[1. 0. 2. 2. 0.]\n",
      " [0. 0. 0. 2. 0.]\n",
      " [1. 2. 1. 2. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 2. 1. 1. 1.]]\n",
      "input_array_conv: [[0. 2. 2. 0. 0.]\n",
      " [0. 0. 2. 0. 0.]\n",
      " [2. 1. 2. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [2. 1. 1. 1. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 2.]\n",
      " [0. 1. 2. 1. 2.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 2. 1. 1.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 2. 0.]\n",
      " [1. 2. 1. 2. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 2. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 2. 0. 0.]\n",
      " [2. 1. 2. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [2. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [0. 2. 1. 2. 0.]\n",
      " [0. 1. 0. 0. 1.]\n",
      " [0. 0. 2. 1. 0.]\n",
      " [0. 0. 1. 2. 2.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [2. 1. 2. 0. 0.]\n",
      " [1. 0. 0. 1. 0.]\n",
      " [0. 2. 1. 0. 1.]\n",
      " [0. 1. 2. 2. 2.]]\n",
      "input_array_conv: [[0. 0. 0. 0. 0.]\n",
      " [1. 2. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [2. 1. 0. 1. 0.]\n",
      " [1. 2. 2. 2. 0.]]\n",
      "input_array_conv: [[0. 2. 1. 2. 0.]\n",
      " [0. 1. 0. 0. 1.]\n",
      " [0. 0. 2. 1. 0.]\n",
      " [0. 0. 1. 2. 2.]\n",
      " [0. 2. 1. 0. 0.]]\n",
      "input_array_conv: [[2. 1. 2. 0. 0.]\n",
      " [1. 0. 0. 1. 0.]\n",
      " [0. 2. 1. 0. 1.]\n",
      " [0. 1. 2. 2. 2.]\n",
      " [2. 1. 0. 0. 1.]]\n",
      "input_array_conv: [[1. 2. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [2. 1. 0. 1. 0.]\n",
      " [1. 2. 2. 2. 0.]\n",
      " [1. 0. 0. 1. 0.]]\n",
      "input_array_conv: [[0. 1. 0. 0. 1.]\n",
      " [0. 0. 2. 1. 0.]\n",
      " [0. 0. 1. 2. 2.]\n",
      " [0. 2. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[1. 0. 0. 1. 0.]\n",
      " [0. 2. 1. 0. 1.]\n",
      " [0. 1. 2. 2. 2.]\n",
      " [2. 1. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "input_array_conv: [[0. 0. 1. 0. 0.]\n",
      " [2. 1. 0. 1. 0.]\n",
      " [1. 2. 2. 2. 0.]\n",
      " [1. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "反向传播后更新得到的filter1: filter weights:\n",
      "array([[[-1.008,  0.99 , -0.009],\n",
      "        [-0.005,  0.994, -0.006],\n",
      "        [-0.006,  0.995,  0.996]],\n",
      "\n",
      "       [[-1.004, -1.001, -0.004],\n",
      "        [-0.01 , -0.009, -0.012],\n",
      "        [-0.002, -1.002, -0.002]],\n",
      "\n",
      "       [[-0.002, -0.002, -1.003],\n",
      "        [-0.005,  0.992, -0.005],\n",
      "        [ 0.993, -1.008, -1.007]]])\n",
      "bias:\n",
      "0.991\n",
      "反向传播后更新得到的filter2: filter weights:\n",
      "array([[[ 9.980e-01,  9.980e-01, -1.001e+00],\n",
      "        [-1.004e+00, -1.007e+00,  9.970e-01],\n",
      "        [-4.000e-03, -1.004e+00,  9.980e-01]],\n",
      "\n",
      "       [[ 0.000e+00,  9.990e-01,  0.000e+00],\n",
      "        [-1.009e+00, -5.000e-03, -1.004e+00],\n",
      "        [-1.004e+00,  1.000e+00,  0.000e+00]],\n",
      "\n",
      "       [[-1.004e+00, -6.000e-03, -5.000e-03],\n",
      "        [-1.002e+00, -5.000e-03,  9.980e-01],\n",
      "        [-1.002e+00, -1.000e-03,  0.000e+00]]])\n",
      "bias:\n",
      "-0.007\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    a, b, cl = init_test()\n",
    "    cl.forward(a)\n",
    "    print(\"前向传播结果:\", cl.output_array)\n",
    "    cl.backward(a, b, IdentityActivator())\n",
    "    cl.update()\n",
    "    print(\"反向传播后更新得到的filter1:\",cl.filters[0])\n",
    "    print(\"反向传播后更新得到的filter2:\",cl.filters[1])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
